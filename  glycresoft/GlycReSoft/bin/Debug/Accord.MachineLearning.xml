<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Accord.MachineLearning</name>
    </assembly>
    <members>
        <member name="T:Accord.MachineLearning.VectorMachines.SupportVectorMachine">
            <summary>
              Sparse Linear Support Vector Machine (SVM)
            </summary>
            <remarks>
            <para>
              Support vector machines (SVMs) are a set of related supervised learning methods
              used for classification and regression. In simple words, given a set of training
              examples, each marked as belonging to one of two categories, a SVM training algorithm
              builds a model that predicts whether a new example falls into one category or the
              other.</para>
            <para>
              Intuitively, an SVM model is a representation of the examples as points in space,
              mapped so that the examples of the separate categories are divided by a clear gap
              that is as wide as possible. New examples are then mapped into that same space and
              predicted to belong to a category based on which side of the gap they fall on.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Support_vector_machine">
                  http://en.wikipedia.org/wiki/Support_vector_machine</a></description></item>
              </list></para>   
            </remarks>
            
            <example>
              <code>
              // Example AND problem
              double[][] inputs =
              {
                  new double[] { 0, 0 }, // 0 and 0: 0 (label -1)
                  new double[] { 0, 1 }, // 0 and 1: 0 (label -1)
                  new double[] { 1, 0 }, // 1 and 0: 0 (label -1)
                  new double[] { 1, 1 }  // 1 and 1: 1 (label +1)
              };
              
              // Dichotomy SVM outputs should be given as [-1;+1]
              int[] labels =
              {
                  // 0,  0,  0, 1
                    -1, -1, -1, 1
              };
              
              // Create a Support Vector Machine for the given inputs
              SupportVectorMachine machine = new SupportVectorMachine(inputs[0].Length);
              
              // Instantiate a new learning algorithm for SVMs
              SequentialMinimalOptimization smo = new SequentialMinimalOptimization(machine, inputs, labels);
              
              // Set up the learning algorithm
              smo.Complexity = 1.0;
              
              // Run the learning algorithm
              double error = smo.Run();
              </code>
            </example>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.ISupportVectorMachine">
            <summary>
              Common interface for Support Vector Machines
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.ISupportVectorMachine.Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.#ctor(System.Int32)">
            <summary>
              Creates a new Support Vector Machine
            </summary>
            <param name="inputs">The number of inputs for the machine.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Compute(System.Double[][])">
            <summary>
              Computes the given inputs to produce the corresponding outputs.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Inputs">
            <summary>
              Gets the number of inputs accepted by this machine.
            </summary>
            <remarks>
              If the number of inputs is zero, this means the machine
              accepts a indefinite number of inputs. This is often the
              case for kernel vector machines using a sequence kernel.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine.SupportVectors">
            <summary>
              Gets or sets the collection of support vectors used by this machine.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Weights">
            <summary>
              Gets or sets the collection of weights used by this machine.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.SupportVectorMachine.Threshold">
            <summary>
              Gets or sets the threshold (bias) term for this machine.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning">
            <summary>
              Common interface for Support Machine Vector learning algorithms.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning.Run">
            <summary>
              Runs the SMO algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning.Run(System.Boolean)">
            <summary>
              Runs the SMO algorithm.
            </summary>
            <param name="computeError">
              True to compute error after the training
              process completes, false otherwise.
            </param>
        </member>
        <member name="T:Accord.MachineLearning.IO.SparseSampleReader">
             <summary>
               Reader for data files containing samples in libsvm's sparse format.
             </summary>
             
             <example>
               <para>
               The following example shows how to read all sparse samples from a file
               and retrieve them as a dense multimensional vector.</para>
               
               <code>
               // Suppose we are going to read a sparse sample file containing
               //  samples which have an actual dimension of 4. Since the samples
               //  are in a sparse format, each entry in the file will probably
               //  have a much lesser number of elements.
               int sampleSize = 4;
            
               // Create a new Sparse Sample Reader to read any given file,
               //  passing the correct dense sample size in the constructor
               SparseSampleReader reader = new SparseSampleReader(file, Encoding.Default, sampleSize);
               
               // Declare a vector to obtain the label
               //  of each of the samples in the file
               int[] labels = null;
               
               // Declare a vector to obtain the description (or comments)
               //  about each of the samples in the file, if present.
               string[] descriptions = null;
               
               // Read the sparse samples and store them in a dense vector array
               double[][] samples = reader.ReadToEnd(out labels, out descriptions);
               </code>
               
               <para>Additionally, it is also possible to read each sample
               individually and sequencially. For this, we can use a while
               loop until we reach the end of the stream.</para>
               
               <code>
               // Suppose we are going to read a sparse sample file containing
               //  samples which have an actual dimension of 4. Since the samples
               //  are in a sparse format, each entry in the file will probably
               //  have a much lesser number of elements.
               int sampleSize = 4;
            
               // Create a new Sparse Sample Reader to read any given file,
               //  passing the correct dense sample size in the constructor
               SparseSampleReader reader = new SparseSampleReader(file, Encoding.Default, sampleSize);
            
               // Declare some variables to receive each current sample
               int label = 0;
               string description;
               double[] sample;
               
               // Read a single sample from the file
               sample = reader.ReadDense(out label, out description);
               
               // Read all other samples from the file
               while (!reader.EndOfStream)
               {
                   sample = reader.ReadDense(out label, out description);
               }
               </code>
             </example>
             
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.#ctor(System.String,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.IO.SparseSampleReader"/> class.
            </summary>
            <param name="path">The complete file path to be read.</param>
            <param name="sampleSize">The size of the feature vectors stored in the file.</param>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.#ctor(System.IO.Stream,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.IO.SparseSampleReader"/> class.
            </summary>
            <param name="stream">The file stream to be read.</param>
            <param name="sampleSize">The size of the feature vectors stored in the file.</param>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.#ctor(System.IO.Stream,System.Text.Encoding,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.IO.SparseSampleReader"/> class.
            </summary>
            <param name="stream">The file stream to be read.</param>
            <param name="encoding">The character encoding to use.</param>
            <param name="sampleSize">The size of the feature vectors stored in the file.</param>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.#ctor(System.String,System.Text.Encoding,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.IO.SparseSampleReader"/> class.
            </summary>
            <param name="path">The complete file path to be read.</param>
            <param name="encoding">The character encoding to use.</param>
            <param name="sampleSize">The size of the feature vectors stored in the file.</param>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.#ctor(System.IO.StreamReader,System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.IO.SparseSampleReader"/> class.
            </summary>
            <param name="reader">A StreamReader containing the file to be read.</param>
            <param name="sampleSize">The size of the feature vectors stored in the file.</param>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadSparse(System.Int32@,System.String@)">
            <summary>
              Reads a sparse sample from the current stream
              and returns it as a sparse vector.
            </summary>
            <param name="label">The label of the sample.</param>
            <param name="description">An optional description accompanying the sample.</param>
            <returns>A vector in sparse representation containing the sample.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadSparse(System.Int32@)">
            <summary>
              Reads a sparse sample from the current stream
              and returns it as a sparse vector.
            </summary>
            <param name="label">The label of the sample.</param>
            <returns>A vector in sparse representation containing the sample.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadDense(System.Int32@,System.String@)">
            <summary>
              Reads a sparse sample from the current stream
              and returns it as a dense vector.
            </summary>
            <param name="label">The label of the sample.</param>
            <param name="description">An optional description accompanying the sample.</param>
            <returns>A vector in dense representation containing the sample.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadDense(System.Int32@)">
            <summary>
              Reads a sparse sample from the current stream
              and returns it as a dense vector.
            </summary>
            <param name="label">The label of the sample.</param>
            <returns>A vector in dense representation containing the sample.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadToEnd(System.Int32[]@)">
            <summary>
              Reads samples from the current position to the end of the stream.
            </summary>
            <param name="labels">An array containing the samples' labels.</param>
            <returns>An array of dense feature vectors.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadToEnd(System.Int32[]@,System.String[]@)">
            <summary>
              Reads samples from the current position to the end of the stream.
            </summary>
            <param name="labels">An array containing the samples' labels.</param>
            <param name="descriptions">An array containing the samples' descriptions.</param>
            <returns>An array of dense feature vectors.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadToEnd(System.Boolean,System.Int32[]@)">
            <summary>
              Reads samples from the current position to the end of the stream.
            </summary>
            <param name="sparse">True to return the feature vectors in a
            sparse representation, false to return them as dense vectors.</param>
            <param name="labels">An array containing the samples' labels.</param>
            <returns>An array of dense feature vectors.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.ReadToEnd(System.Boolean,System.Int32[]@,System.String[]@)">
            <summary>
              Reads samples from the current position to the end of the stream.
            </summary>
            <param name="sparse">True to return the feature vectors in a
            sparse representation, false to return them as dense vectors.</param>
            <param name="labels">An array containing the samples' labels.</param>
            <param name="descriptions">An array containing the samples' descriptions.</param>
            <returns>An array of dense feature vectors.</returns>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.Dispose">
            <summary>
            Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.IO.SparseSampleReader.Dispose(System.Boolean)">
            <summary>
              Releases unmanaged and - optionally - managed resources
            </summary>
            <param name="disposing"><c>true</c> to release both managed and unmanaged resources; <c>false</c> to release only unmanaged resources.</param>
        </member>
        <member name="P:Accord.MachineLearning.IO.SparseSampleReader.BaseStream">
            <summary>
              Returns the underlying stream.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.IO.SparseSampleReader.EndOfStream">
            <summary>
              Gets a value that indicates whether the current
              stream position is at the end of the stream.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.CrossvalidationFittingFunction`1">
            <summary>
              Fitting function delegate.
            </summary>
            <param name="trainingSamples">
              The sample indexes to be used as training samples in
              the model fitting procedure.
            </param>
            <param name="validationSamples">
              The sample indexes to be used as validation samples in
              the model fitting procedure.
            </param>
            <remarks>
              The fitting function is called during the Cross-validation
              procedure to fit a model with the given set of samples for
              training and validation.
            </remarks>
        </member>
        <member name="T:Accord.MachineLearning.Crossvalidation`1">
             <summary>
               k-Fold Cross-Validation.
             </summary>
             <remarks>
             <para>
               Cross-validation is a technique for estimating the performance of a predictive
               model. It can be used to measure how the results of a statistical analysis will
               generalize to an independent data set. It is mainly used in settings where the
               goal is prediction, and one wants to estimate how accurately a predictive model
               will perform in practice.</para>
             <para>
               One round of cross-validation involves partitioning a sample of data into
               complementary subsets, performing the analysis on one subset (called the
               training set), and validating the analysis on the other subset (called the
               validation set or testing set). To reduce variability, multiple rounds of 
               cross-validation are performed using different partitions, and the validation 
               results are averaged over the rounds.</para> 
               
             <para>
               References:
               <list type="bullet">
                 <item><description><a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">
                   http://en.wikipedia.org/wiki/Cross-validation_(statistics)</a></description></item>
                 <item><description><a href="http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html">
                   http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html</a></description></item>
               </list></para> 
             </remarks>
             
             <example>
               <code>
               //Example binary data
               double[][] data =
               {
                    new double[] { -1, -1 }, new double[] {  1, -1 },
                    new double[] { -1,  1 }, new double[] {  1,  1 },
                    new double[] { -1, -1 }, new double[] {  1, -1 },
                    new double[] { -1,  1 }, new double[] {  1,  1 },
                    new double[] { -1, -1 }, new double[] {  1, -1 },
                    new double[] { -1,  1 }, new double[] {  1,  1 },
                    new double[] { -1, -1 }, new double[] {  1, -1 },
                    new double[] { -1,  1 }, new double[] {  1,  1 },
                };
            
                int[] xor = // result of xor
                {
                    -1,  1,
                     1, -1,
                    -1,  1,
                     1, -1,
                    -1,  1,
                     1, -1,
                    -1,  1,
                     1, -1,
                };
            
            
                // Create a new Cross-validation algorithm passing the data set size and the number of folds
                var crossvalidation = new Crossvalidation&lt;KernelSupportVectorMachine>(data.Length, 3);
            
                // Define a fitting function using Support Vector Machines
                crossvalidation.Fitting = delegate(int[] trainingSet, int[] validationSet)
                {
                    // The trainingSet and validationSet arguments specifies the
                    // indices of the original data set to be used as training and
                    // validation sets, respectively.
                    double[][] trainingInputs = data.Submatrix(trainingSet);
                    int[] trainingOutputs = xor.Submatrix(trainingSet);
            
                    double[][] validationInputs = data.Submatrix(validationSet);
                    int[] validationOutputs = xor.Submatrix(validationSet);
            
                    // Create a Kernel Support Vector Machine to operate on this set
                    var svm = new KernelSupportVectorMachine(new Polynomial(2), 2);
            
                    // Create a training algorithm and learn this set
                    var smo = new SequentialMinimalOptimization(svm, trainingInputs, trainingOutputs);
            
                    double trainingError = smo.Run();
                    double validationError = smo.ComputeError(validationInputs, validationOutputs);
            
                    // Return a new information structure containing the model and the errors achieved.
                    return new CrossvalidationInfo&lt;KernelSupportVectorMachine>(svm, trainingError, validationError);
                };
            
             
                // Compute the cross-validation
                crossvalidation.Compute();
            
                // Get the average training and validation errors
                double errorTraining   = crossvalidation.TrainingError;
                double errorValidation = crossvalidation.ValidationError;
               </code>
             </example>
             
        </member>
        <member name="M:Accord.MachineLearning.Crossvalidation`1.#ctor(System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            <param name="size">The complete dataset for training and testing.</param>
        </member>
        <member name="M:Accord.MachineLearning.Crossvalidation`1.#ctor(System.Int32,System.Int32)">
            <summary>
              Creates a new k-fold cross-validation algorithm.
            </summary>
            <param name="size">The complete dataset for training and testing.</param>
            <param name="folds">The number of folds, usually denoted as <c>k</c> (default is 10).</param>
        </member>
        <member name="M:Accord.MachineLearning.Crossvalidation`1.Compute">
            <summary>
              Computes the cross validation algorithm.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.Fitting">
            <summary>
              Gets or sets the model fitting function.
            </summary>
            <remarks>
              The fitting function should accept an array of integers containing the
              indexes for the training samples, an array of integers containing the
              indexes for the validation samples and should return information about
              the model fitted using those two subsets of the available data.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.Models">
            <summary>
              Gets the models created for each fold of the cross validation.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.ValidationError">
            <summary>
              Gets the average validation error.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.TrainingError">
            <summary>
              Gets the average training error.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.Folds">
            <summary>
              Gets the array of indexes contained in each fold.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.Crossvalidation`1.K">
            <summary>
              Gets the number of folds in the k-fold cross validation.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.CrossvalidationInfo`1">
            <summary>
              Information class to store the training and validation errors of a model. 
            </summary>
            <typeparam name="TModel">The type of the model.</typeparam>
        </member>
        <member name="M:Accord.MachineLearning.CrossvalidationInfo`1.#ctor(`0,System.Double,System.Double)">
            <summary>
              Creates a new CrossvalidationInfo class.
            </summary>
            <param name="model">The fitted model.</param>
            <param name="trainingError">The training error for the model.</param>
            <param name="validationError">The validation error for the model.</param>
        </member>
        <member name="P:Accord.MachineLearning.CrossvalidationInfo`1.Model">
            <summary>
              Gets the model.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.CrossvalidationInfo`1.ValidationError">
            <summary>
              Gets the validation error for the model.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.CrossvalidationInfo`1.TrainingError">
            <summary>
              Gets the training error for the model.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.CrossvalidationInfo`1.Tag">
            <summary>
              Gets or sets a tag for user-defined information.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.RANSAC`1">
            <summary>
              Multipurpose RANSAC algorithm.
            </summary>
            <typeparam name="TModel">The model type to be trained by RANSAC.</typeparam>
            <remarks>
              RANSAC is an abbreviation for "RANdom SAmple Consensus". It is an iterative
              method to estimate parameters of a mathematical model from a set of observed
              data which contains outliers. It is a non-deterministic algorithm in the sense
              that it produces a reasonable result only with a certain probability, with this
              probability increasing as more iterations are allowed.
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32,System.Double)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
            <param name="threshold">
              The minimum distance between a data point and
              the model used to decide whether the point is
              an inlier or not.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.#ctor(System.Int32,System.Double,System.Double)">
            <summary>
              Constructs a new RANSAC algorithm.
            </summary>
            <param name="minSamples">
              The minimum number of samples from the data
              required by the fitting function to fit a model.
            </param>
            <param name="threshold">
              The minimum distance between a data point and
              the model used to decide whether the point is
              an inlier or not.
            </param>
            <param name="probability">
              The probability of obtaining a random sample of
              the input points that contains no outliers.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.Compute(System.Int32)">
            <summary>
              Computes the model using the RANSAC algorithm.
            </summary>
            <param name="size">The total number of points in the data set.</param>
        </member>
        <member name="M:Accord.MachineLearning.RANSAC`1.Compute(System.Int32,System.Int32[]@)">
            <summary>
              Computes the model using the RANSAC algorithm.
            </summary>
            <param name="size">The total number of points in the data set.</param>
            <param name="inliers">The indexes of the outlier points in the data set.</param>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Fitting">
            <summary>
              Model fitting function.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Degenerate">
            <summary>
              Degenerative set detection function.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Distances">
            <summary>
              Distance function.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Threshold">
            <summary>
              Gets or sets the minimum distance between a data point and
              the model used to decide whether the point is an inlier or not.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Samples">
            <summary>
              Gets or sets the minimum number of samples from the data
              required by the fitting function to fit a model.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.MaxSamplings">
            <summary>
              Maximum number of attempts to select a non-degenerate data set.
            </summary>
            <remarks>
              The default value is 100.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.MaxEvaluations">
            <summary>
              Maximum number of iterations.
            </summary>
            <remarks>
              The default value is 1000.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.RANSAC`1.Probability">
            <summary>
              Gets or sets the probability of obtaining a random
              sample of the input points that contains no outliers.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SupportVectorMachineLearningConfigurationFunction">
            <summary>
              Configuration function to configure the learning algorithms
              for each of the Kernel Support Vector Machines used in this
              Multi-class Support Vector Machine.
            </summary>
            <param name="inputs">The input data for the learning algorithm.</param>
            <param name="outputs">The output data for the learning algorithm.</param>
            <param name="machine">The machine for the learning algorithm.</param>
            <param name="class1">The class index corresponding to the negative values
                in the output values contained in <paramref name="outputs"/>.</param>
            <param name="class2">The class index corresponding to the positive values
                in the output values contained in <paramref name="outputs"/>.</param>
            <returns>
              The configured <see cref="T:Accord.MachineLearning.VectorMachines.Learning.ISupportVectorMachineLearning"/> algorithm
              to be used to train the given <see cref="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine"/>.
            </returns>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning">
             <summary>
               One-against-one Multi-class Support Vector Machine Learning Algorithm
             </summary>
             
             <remarks>
               This class can be used to train Kernel Support Vector Machines with
               any algorithm using a one-against-one strategy. The underlying training
               algorithm can be configured by defining the Configure delegate.
             </remarks>
             
             <example>
               <code>
               // Sample data
               //   The following is simple auto association function
               //   where each input correspond to its own class. This
               //   problem should be easily solved by a Linear kernel.
            
               // Sample input data
               double[][] inputs =
               {
                   new double[] { 0 },
                   new double[] { 3 },
                   new double[] { 1 },
                   new double[] { 2 },
               };
               
               // Output for each of the inputs
               int[] outputs = { 0, 3, 1, 2 };
               
               
               // Create a new Linear kernel
               IKernel kernel = new Linear();
               
               // Create a new Multi-class Support Vector Machine with one input,
               //  using the linear kernel and for four disjoint classes.
               var machine = new MulticlassSupportVectorMachine(1, kernel, 4);
               
               // Create the Multi-class learning algorithm for the machine
               var teacher = new MulticlassSupportVectorLearning(machine, inputs, outputs);
               
               // Configure the learning algorithm to use SMO to train the
               //  underlying SVMs in each of the binary class subproblems.
               teacher.Algorithm = (svm, classInputs, classOutputs, i, j) =>
                   new SequentialMinimalOptimization(svm, classInputs, classOutputs);
               
               // Run the learning algorithm
               double error = teacher.Run();
               </code>
             </example>
             
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.#ctor(Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Constructs a new Multi-class Support Vector Learning algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Run">
            <summary>
              Runs the one-against-one learning algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Run(System.Boolean)">
            <summary>
              Runs the one-against-one learning algorithm.
            </summary>
            <param name="computeError">
              True to compute error after the training
              process completes, false otherwise. Default is true.
            </param>
            <returns>
              The sum of squares error rate for
              the resulting support vector machine.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Compute the error ratio.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning.Algorithm">
            <summary>
              Gets or sets the configuration function for the learning algorithm.
            </summary>
            <remarks>
              The configuration function should return a properly configured ISupportVectorMachineLearning
              algorithm using the given support vector machine and the input and output data.
            </remarks>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm
            </summary>
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class follows the original algorithm by Platt as strictly as possible.</para>
             
            <para>
              References:
              <list type="bullet">
                <item><description>
                  <a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization">
                  http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization</a></description></item>
                <item><description>
                  <a href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf">
                  http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf</a></description></item>
                <item><description>
                  <a href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf">
                  http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf</a></description></item>
                </list></para>  
            </remarks>
            
            <example>
              <code>
              // Example XOR problem
              double[][] inputs =
              {
                  new double[] { 0, 0 }, // 0 xor 0: 1 (label +1)
                  new double[] { 0, 1 }, // 0 xor 1: 0 (label -1)
                  new double[] { 1, 0 }, // 1 xor 0: 0 (label -1)
                  new double[] { 1, 1 }  // 1 xor 1: 1 (label +1)
              };
               
              // Dichotomy SVM outputs should be given as [-1;+1]
              int[] labels =
              {
                     1, -1, -1, 1
              };
             
              // Create a Kernel Support Vector Machine for the given inputs
              KernelSupportVectorMachine machine = new KernelSupportVectorMachine(new Gaussian(0.1), inputs[0].Length);
            
              // Instantiate a new learning algorithm for SVMs
              SequentialMinimalOptimization smo = new SequentialMinimalOptimization(machine, inputs, labels);
            
              // Set up the learning algorithm
              smo.Complexity = 1.0;
            
              // Run the learning algorithm
              double error = smo.Run();
             </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Int32[])">
            <summary>
              Initializes a new instance of a Sequential Minimal Optimization (SMO) algorithm.
            </summary>
            <param name="machine">A Support Vector Machine.</param>
            <param name="inputs">The input data points as row vectors.</param>
            <param name="outputs">The classification label for each data point.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Run(System.Boolean)">
            <summary>
              Runs the SMO algorithm.
            </summary>
            <param name="computeError">
              True to compute error after the training
              process completes, false otherwise. Default is true.
            </param>
            <returns>
              The misclassification error rate of
              the resulting support vector machine.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Run">
            <summary>
              Runs the SMO algorithm.
            </summary>
            <returns>
              The misclassification error rate of
              the resulting support vector machine.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.ComputeError(System.Double[][],System.Int32[])">
            <summary>
              Computes the error ratio for a given set of input and outputs.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.examineExample(System.Int32)">
            <summary>
             Chooses which multipliers to optimize using heuristics.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.takeStep(System.Int32,System.Int32)">
            <summary>
              Analytically solves the optimization problem for two Lagrange multipliers.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.compute(System.Double[])">
            <summary>
              Computes the SVM output for a given point.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Complexity">
            <summary>
              Complexity (cost) parameter C. Increasing the value of C forces the creation
              of a more accurate model that may not generalize well. Default value is the
              number of examples divided by the trace of the kernel matrix.
            </summary>
            <remarks>
              The cost parameter C controls the trade off between allowing training
              errors and forcing rigid margins. It creates a soft margin that permits
              some misclassifications. Increasing the value of C increases the cost of
              misclassifying points and forces the creation of a more accurate model
              that may not generalize well.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.UseComplexityHeuristic">
            <summary>
              Gets or sets a value indicating whether the Complexity parameter C
              should be computed automatically by employing an heuristic rule.
            </summary>
            <value>
            	<c>true</c> if complexity should be computed automatically; otherwise, <c>false</c>.
            </value>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Epsilon">
            <summary>
              Insensitivity zone ε. Increasing the value of ε can result in fewer support
              vectors in the created model. Default value is 1e-3.
            </summary>
            <remarks>
              Parameter ε controls the width of the ε-insensitive zone, used to fit the training
              data. The value of ε can affect the number of support vectors used to construct the
              regression function. The bigger ε, the fewer support vectors are selected. On the
              other hand, bigger ε-values results in more flat estimates.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimization.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-3.
            </summary>
            <remarks>
              The criterion for completing the model training process. The default is 0.001.
            </remarks>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm for Regression
            </summary>
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class incorporates modifications in the original SMO algorithm to solve
              regression problems as suggested by Alex J. Smola and Bernhard Scholkopf and
              further modifications for better performance by Shevade et al.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                 A. J. Smola and B. Scholkopf. A Tutorial on Support Vector Regression. NeuroCOLT2
                 Technical Report Series, 1998. Available on: <a href="http://www.kernel-machines.org/publications/SmoSch98c">
                 http://www.kernel-machines.org/publications/SmoSch98c</a></description></item>
                <item><description>
                 S.K. Shevade et al. Improvements to SMO Algorithm for SVM Regression, 1999. Available
                 on: <a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz">
                 http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz</a></description></item>
                <item><description>
                 G. W. Flake, S. Lawrence. Efficient SVM Regression Training with SMO.
                 Available on: <a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf">
                 http://www.keerthis.com/smoreg_ieee_shevade_00.pdf</a></description></item>
              </list></para>
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Double[])">
            <summary>
              Initializes a new instance of a Sequential Minimal Optimization (SMO) algorithm.
            </summary>
            <param name="machine">A Support Vector Machine.</param>
            <param name="inputs">The input data points as row vectors.</param>
            <param name="outputs">The classification label for each data point.</param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Run(System.Boolean)">
            <summary>
              Runs the SMO algorithm.
            </summary>
            <param name="computeError">
              True to compute error after the training
              process completes, false otherwise. Default is true.
            </param>
            <returns>
              The sum of squares error rate for
              the resulting support vector machine.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Run">
            <summary>
              Runs the SMO algorithm.
            </summary>
            <returns>
              The sum of squares error rate for
              the resulting support vector machine.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.ComputeError(System.Double[][],System.Double[])">
            <summary>
              Computes the error ratio for a given set of input and outputs.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.examineExample(System.Int32)">
            <summary>
             Chooses which multipliers to optimize using heuristics.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.takeStep(System.Int32,System.Int32)">
            <summary>
              Analytically solves the optimization problem for two Lagrange multipliers.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.compute(System.Double[])">
            <summary>
              Computes the SVM output for a given point.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Complexity">
            <summary>
              Complexity (cost) parameter C. Increasing the value of C forces the creation
              of a more accurate model that may not generalize well. Default value is 1.
            </summary>
            <remarks>
              The cost parameter C controls the trade off between allowing training
              errors and forcing rigid margins. It creates a soft margin that permits
              some misclassifications. Increasing the value of C increases the cost of
              misclassifying points and forces the creation of a more accurate model
              that may not generalize well.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Epsilon">
            <summary>
              Insensitivity zone ε. Increasing the value of ε can result in fewer support
              vectors in the created model. Default value is 1e-3.
            </summary>
            <remarks>
              Parameter ε controls the width of the ε-insensitive zone, used to fit the training
              data. The value of ε can affect the number of support vectors used to construct the
              regression function. The bigger ε, the fewer support vectors are selected. On the
              other hand, bigger ε-values results in more flat estimates.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-3.
            </summary>
            <remarks>
              The criterion for completing the model training process. The default is 0.001.
            </remarks>
        </member>
        <member name="T:Accord.MachineLearning.KMeans">
             <summary>
               K-Means algorithm.
             </summary>
             <remarks>
             <para>
               In statistics and machine learning, k-means clustering is a method
               of cluster analysis which aims to partition n observations into k 
               clusters in which each observation belongs to the cluster with the
               nearest mean.</para>
             <para>
               It is similar to the expectation-maximization algorithm for mixtures
               of Gaussians in that they both attempt to find the centers of natural
               clusters in the data as well as in the iterative refinement approach
               employed by both algorithms.</para> 
             
             <para>
               The algorithm is composed of the following steps:
               <list type="number">
                 <item><description>
                     Place K points into the space represented by the objects that are
                     being clustered. These points represent initial group centroids.
                 </description></item>
                 <item><description>
                     Assign each object to the group that has the closest centroid.
                 </description></item>
                 <item><description>
                     When all objects have been assigned, recalculate the positions
                     of the K centroids.
                 </description></item>
                 <item><description>
                     Repeat Steps 2 and 3 until the centroids no longer move. This
                     produces a separation of the objects into groups from which the
                     metric to be minimized can be calculated.
                 </description></item>
               </list></para>
             
             <para>
               This particular implementation uses the squared euclidean distance
               as a similarity measure in order to form clusters. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   http://en.wikipedia.org/wiki/K-means_clustering </description></item>
                 <item><description>
                   http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/kmeans.html </description></item>
               </list></para>
             </remarks>
             <example>
               How to perform clustering with K-Means.
               <code>
               // Declare some observations
               double[][] observations = 
               {
                   new double[] { -5, -2, -1 },
                   new double[] { -5, -5, -6 },
                   new double[] {  2,  1,  1 },
                   new double[] {  1,  1,  2 },
                   new double[] {  1,  2,  2 },
                   new double[] {  3,  1,  2 },
                   new double[] { 11,  5,  4 },
                   new double[] { 15,  5,  6 },
                   new double[] { 10,  5,  6 },
               };
              
               // Create a new K-Means algorithm with 3 clusters 
               KMeans kmeans = new KMeans(3);
              
               // Compute the algorithm, retrieving an integer array
               //  containing the labels for each of the observations
               int[] labels = kmeans.Compute(observations);
              
               // As result, the first two observations should belong to the
               // same cluster (thus having the same label). The same should
               // happen to the next four observations and to the last three.
               </code>
             </example>
            
        </member>
        <member name="M:Accord.MachineLearning.KMeans.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of K-Means algorithm
            </summary>
            <param name="k">The number of clusters to divide input data.</param>        
        </member>
        <member name="M:Accord.MachineLearning.KMeans.#ctor(System.Int32,System.Func{System.Double[],System.Double[],System.Double})">
            <summary>
              Initializes a new instance of KMeans algorithm
            </summary>
            <param name="k">The number of clusters to divide input data.</param>       
            <param name="distance">The distance function to use. Default is to
            use the <see cref="M:Accord.Math.Distance.SquareEuclidean(System.Double[],System.Double[])"/> distance.</param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Randomize(System.Double[][])">
            <summary>
              Randomizes the clusters inside a dataset.
            </summary>
            <param name="data">The data to randomize the algorithm.</param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][])">
            <summary>
              Divides the input data into K clusters. 
            </summary>     
            <param name="data">The data where to compute the algorithm.</param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][],System.Double@)">
            <summary>
              Divides the input data into K clusters. 
            </summary>    
            <param name="data">The data where to compute the algorithm.</param>
            <param name="error">
              The average square distance from the
              data points to the clusters' centroids.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][],System.Double)">
            <summary>
              Divides the input data into K clusters. 
            </summary>     
            <param name="data">The data where to compute the algorithm.</param>
            <param name="threshold">The relative convergence threshold
            for the algorithm. Default is 1e-5.</param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Compute(System.Double[][],System.Double,System.Double@)">
            <summary>
              Divides the input data into K clusters. 
            </summary>  
            <param name="data">The data where to compute the algorithm.</param>
            <param name="threshold">The relative convergence threshold
            for the algorithm. Default is 1e-5.</param>
            <param name="error">
              The average square distance from the
              data points to the clusters' centroids.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Nearest(System.Double[])">
            <summary>
              Returns the closest cluster to an input vector.
            </summary>
            <param name="point">The input vector.</param>
            <returns>
              The index of the nearest cluster
              to the given data point. </returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Nearest(System.Double[][])">
            <summary>
              Returns the closest clusters to an input vector array.
            </summary>
            <param name="points">The input vector array.</param>
            <returns>
              An array containing the index of the nearest cluster
              to the corresponding point in the input array.</returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.Error(System.Double[][],System.Int32[])">
            <summary>
              Calculates the average square distance from the data points
              to the clusters' centroids.
            </summary>
            <remarks>
              The average distance from centroids can be used as a measure
              of the "goodness" of the clusterization. The more the data
              are aggregated around the centroids, the less the average
              distance.
            </remarks>
            <returns>
              The average square distance from the data points to the
              clusters' centroids.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.KMeans.converged(System.Double[][],System.Double[][],System.Double)">
            <summary>
              Determines if the algorithm has converged by comparing the
              centroids between two consecutive iterations.
            </summary>
            <param name="centroids">The previous centroids.</param>
            <param name="newCentroids">The new centroids.</param>
            <param name="threshold">A convergence threshold.</param>
            <returns>Returns <see langword="true"/> if all centroids had a percentage change
               less than <see param="threshold"/>. Returns <see langword="false"/> otherwise.</returns>
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Clusters">
            <summary>
              Gets the clusters found by K-means.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeans.K">
            <summary>
              Gets the number of clusters.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Dimension">
            <summary>
              Gets the dimensionality of the data space.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeans.Distance">
            <summary>
              Gets or sets the distance function used
              as a distance metric between data points.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.KMeansCluster">
            <summary>
              K-means' Cluster
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansCluster.Index">
            <summary>
              Gets the label for this cluster.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeansCluster.Mean">
            <summary>
              Gets the cluster's centroid.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeansCluster.Covariance">
            <summary>
              Gets the cluster's variance-covariance matrix.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.KMeansCluster.Proportion">
            <summary>
              Gets the proportion of samples in the cluster.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.KMeansClusterCollection">
            <summary>
              K-means Cluster Collection.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Covariances">
            <summary>
              Gets the clusters' variance-covariance matrices.
            </summary>
            <value>The clusters' variance-covariance matrices.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Centroids">
            <summary>
              Gets or sets the clusters' centroids.
            </summary>
            <value>The clusters' centroids.</value>
        </member>
        <member name="P:Accord.MachineLearning.KMeansClusterCollection.Proportions">
            <summary>
              Gets the proportion of samples in each cluster.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GaussianMixtureModel">
            <summary>
              Gaussian Mixture Model Clustering.
            </summary>
            <remarks>
              Gaussian Mixture Models are one of most widely used model-based 
              clustering methods. This specialized class provides a wrap-up
              around the
              <see cref="T:Accord.Statistics.Distributions.Multivariate.Mixture`1">
              Mixture&lt;NormalDistribution&gt;</see> distribution and provides
              mixture initialization using the K-Means clustering algorithm.
            </remarks>
            
            <example>
              <code>
              // Create a new Gaussian Mixture Model with 2 components
              GaussianMixtureModel gmm = new GaussianMixtureModel(2);
              
              // Compute the model (estimate)
              gmm.Compute(samples, 0.0001);
              
              // Classify a single sample
              int c = gmm.Classify(sample);
              </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.GetMixtureDistribution">
            <summary>
              Gets a mixture distribution modeled
              by this Gaussian Mixture Model.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.#ctor(System.Int32)">
            <summary>
              Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModel"/> class.
            </summary>
            <param name="components">
              The number of clusters in the clusterization problem. This will be
              used to set the number of components in the mixture model.</param>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(System.Double[][],System.Double)">
            <summary>
              Initializes the model with initial values obtained 
              throught a run of the K-Means clustering algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Initialize(Accord.MachineLearning.KMeans)">
            <summary>
              Initializes the model with initial values obtained 
              throught a run of the K-Means clustering algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][])">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],System.Double)">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],System.Double,System.Double)">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Compute(System.Double[][],Accord.MachineLearning.GaussianMixtureModelOptions)">
            <summary>
              Divides the input data into K clusters modeling each
              cluster as a multivariate Gaussian distribution. 
            </summary>     
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Classify(System.Double[])">
            <summary>
              Returns the most likely clusters of an observation.
            </summary>
            <param name="observation">An input observation.</param>
            <returns>
              The index of the most likely cluster
              of the given observation. </returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Classify(System.Double[],System.Double[]@)">
            <summary>
              Returns the most likely clusters of an observation.
            </summary>
            <param name="observation">An input observation.</param>
            <param name="responses">The likelihood responses for each cluster.</param>
            <returns>
              The index of the most likely cluster
              of the given observation. </returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModel.Classify(System.Double[][])">
            <summary>
              Returns the most likely clusters for an array of observations.
            </summary>
            <param name="observations">An set of observations.</param>
            <returns>
              An array containing the index of the most likely cluster
              for each of the given observations. </returns>
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModel.Gaussians">
            <summary>
              Gets the Gaussian components of the mixture model.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GaussianMixtureModelOptions">
            <summary>
              Options for Gaussian Mixture Model fitting.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GaussianMixtureModelOptions.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.GaussianMixtureModelOptions"/> class.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.Threshold">
            <summary>
              Gets or sets the convergence criterion for the
              Expectation-Maximization algorithm. Default is 1e-3.
            </summary>
            <value>The convergence threshold.</value>
        </member>
        <member name="P:Accord.MachineLearning.GaussianMixtureModelOptions.NormalOptions">
            <summary>
              Gets or sets the fitting options for the component
              Gaussian distributions of the mixture model.
            </summary>
            <value>The fitting options for inner Gaussian distributions.</value>
        </member>
        <member name="T:Accord.MachineLearning.GaussianCluster">
            <summary>
              Gaussian Mixture Model Cluster
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.GaussianCluster.Probability(System.Double[])">
            <summary>
              Gets the probability density function of the
              underlying Gaussian probability distribution 
              evaluated in point <c>x</c>.
            </summary>
            <param name="x">An observation.</param>
            <returns>
              The probability of <c>x</c> occurring
              in the weighted Gaussian distribution.
            </returns>
        </member>
        <member name="M:Accord.MachineLearning.GaussianCluster.GetDistribution">
            <summary>
              Gets the normal distribution associated with this cluster.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GaussianCluster.Index">
            <summary>
              Gets the label for this cluster.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GaussianCluster.Mean">
            <summary>
              Gets the cluster's mean.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GaussianCluster.Covariance">
            <summary>
              Gets the cluster's variance-covariance matrix.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GaussianCluster.Proportion">
            <summary>
              Gets the mixture coefficient for the cluster distribution.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GaussianClusterCollection">
            <summary>
              Gaussian Mixture Model Cluster Collection.
            </summary>
            
        </member>
        <member name="T:Accord.MachineLearning.GridSearchFittingFunction`1">
            <summary>
              Delegate for Grid search fitting function.
            </summary>
            <typeparam name="TModel">The type of the model to fit.</typeparam>
            <param name="parameters">The collection of parameters to be used in the fitting process.</param>
            <param name="error">The error (or any other performance measure) returned by the model.</param>
            <returns>The model fitted to the data using the given parameters.</returns>
        </member>
        <member name="T:Accord.MachineLearning.GridSearch`1">
             <summary>
               Grid Search for automatic parameter tuning.
             </summary>
             <remarks>
               Grid Search tries to find the best combination of parameters across
               a range of possible values that produces the best fit model. If there
               are two parameters, each with 10 possible values, Grid Search will try
               an exhaustive evaluation of the model using every combination of points,
               resulting in 100 model fits.
             </remarks>
             
             <typeparam name="TModel">The type of the model to be tuned.</typeparam>
             
             <example>
               How to fit a Kernel Support Vector Machine using Grid Search.
               <code>
               // Example binary data
               double[][] inputs =
               {
                   new double[] { -1, -1 },
                   new double[] { -1,  1 },
                   new double[] {  1, -1 },
                   new double[] {  1,  1 }
               };
            
               int[] xor = // xor labels
               {
                   -1, 1, 1, -1
               };
            
               // Declare the parameters and ranges to be searched
               GridSearchRange[] ranges = 
               {
                   new GridSearchRange("complexity", new double[] { 0.00000001, 5.20, 0.30, 0.50 } ),
                   new GridSearchRange("degree",     new double[] { 1, 10, 2, 3, 4, 5 } ),
                   new GridSearchRange("constant",   new double[] { 0, 1, 2 } )
               };
            
            
               // Instantiate a new Grid Search algorithm for Kernel Support Vector Machines
               var gridsearch = new GridSearch&lt;KernelSupportVectorMachine>(ranges);
            
               // Set the fitting function for the algorithm
               gridsearch.Fitting = delegate(GridSearchParameterCollection parameters, out double error)
               {
                   // The parameters to be tried will be passed as a function parameter.
                   int degree = (int)parameters["degree"].Value;
                   double constant = parameters["constant"].Value;
                   double complexity = parameters["complexity"].Value;
            
                   // Use the parameters to build the SVM model
                   Polynomial kernel = new Polynomial(degree, constant);
                   KernelSupportVectorMachine ksvm = new KernelSupportVectorMachine(kernel, 2);
            
                   // Create a new learning algorithm for SVMs
                   SequentialMinimalOptimization smo = new SequentialMinimalOptimization(ksvm, inputs, xor);
                   smo.Complexity = complexity;
            
                   // Measure the model performance to return as an out parameter
                   error = smo.Run();
            
                   return ksvm; // Return the current model
               };
            
            
               // Declare some out variables to pass to the grid search algorithm
               GridSearchParameterCollection bestParameters; double minError;
            
               // Compute the grid search to find the best Support Vector Machine
               KernelSupportVectorMachine bestModel = gridsearch.Compute(out bestParameters, out minError);
               </code>
             </example>
             
        </member>
        <member name="M:Accord.MachineLearning.GridSearch`1.#ctor(Accord.MachineLearning.GridSearchRange[])">
            <summary>
              Constructs a new Grid search algorithm.
            </summary>
            <param name="parameterRanges">The range of parameters to search.</param>
        </member>
        <member name="M:Accord.MachineLearning.GridSearch`1.Compute(Accord.MachineLearning.GridSearchParameterCollection@,System.Double@)">
            <summary>
              Searches for the best combination of parameters that results in the most accurate model.
            </summary>
            <param name="bestParameters">The best combination of parameters found by the grid search.</param>
            <param name="error">The minimum error of the best model found by the grid search.</param>
            <returns>The best model found during the grid search.</returns>
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.Fitting">
            <summary>
              A function that fits a model using the given parameters.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearch`1.ParameterRanges">
            <summary>
              The range of parameters to consider during search.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GridSearchParameter">
            <summary>
              Contains the name and value of a parameter that should be used during fitting.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.#ctor(System.String,System.Double)">
            <summary>
              Constructs a new parameter.
            </summary>
            <param name="name">The name for the parameter.</param>
            <param name="value">The value for the parameter.</param>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.Equals(System.Object)">
            <summary>
              Determines whether the specified object is equal
              to the current GridsearchParameter object.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.GetHashCode">
            <summary>
              Returns the hash code for this GridsearchParameter
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.op_Equality(Accord.MachineLearning.GridSearchParameter,Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Compares two GridsearchParameters for equality.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameter.op_Inequality(Accord.MachineLearning.GridSearchParameter,Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Compares two GridsearchParameters for inequality.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearchParameter.Name">
            <summary>
              Gets the name of the parameter
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearchParameter.Value">
            <summary>
              Gets the value of the parameter.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GridSearchRange">
            <summary>
              Represents a range of parameters to be should be tried during a grid search.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.#ctor(System.String,System.Double,System.Double,System.Double)">
            <summary>
              Constructs a new GridsearchRange object.
            </summary>
            <param name="name">The name for this parameter.</param>
            <param name="start">The starting value for this range.</param>
            <param name="end">The end value for this range.</param>
            <param name="step">The step size for this range.</param>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.#ctor(System.String,System.Double[])">
            <summary>
              Constructs a new GridsearchRange object.
            </summary>
            <param name="name">The name for this parameter.</param>
            <param name="values">The array of values to try.</param>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRange.GetParameters">
            <summary>
              Gets the array of GridsearchParameters to try.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearchRange.Name">
            <summary>
              Gets or sets the name of the parameter from which the range belongs to.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.GridSearchRange.Values">
            <summary>
              Gets or sets the range of values that should be tested for this parameter.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GridSearchRangeCollection">
            <summary>
              GridsearchRange collection.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.#ctor(Accord.MachineLearning.GridSearchRange[])">
            <summary>
              Constructs a new collection of GridsearchRange objects.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.GetKeyForItem(Accord.MachineLearning.GridSearchRange)">
            <summary>
              Returns the identifying value for an item on this collection.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchRangeCollection.Add(System.String,System.Double[])">
            <summary>
              Adds a parameter range to the end of the GridsearchRangeCollection.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.GridSearchParameterCollection">
            <summary>
              GridsearchParameter collection.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.#ctor(Accord.MachineLearning.GridSearchParameter[])">
            <summary>
              Constructs a new collection of GridsearchParameter objects.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.#ctor(System.Collections.Generic.IEnumerable{Accord.MachineLearning.GridSearchParameter})">
            <summary>
              Constructs a new collection of GridsearchParameter objects.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.GridSearchParameterCollection.GetKeyForItem(Accord.MachineLearning.GridSearchParameter)">
            <summary>
              Returns the identifying value for an item on this collection.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine">
             <summary>
               One-against-one Multi-class Kernel Support Vector Machine Classifier.
             </summary>
             <remarks>
             <para>
               The Support Vector Machine is by nature a binary classifier. One of the ways
               to extend the original SVM algorithm to multiple classes is to build a one-
               against-one scheme where multiple SVMs specialize to recognize each of the
               available classes. By using a competition scheme, the original multi-class
               classification problem is then reduced to <c>n*(n/2)</c> smaller binary problems.</para>
             <para>
               Currently this class supports only Kernel machines as the underlying classifiers.
               If a Linear Support Vector Machine is needed, specify a Linear kernel in the
               constructor at the moment of creation. </para>
               
             <para>
               References:
               <list type="bullet">
                 <item><description>
                   <a href="http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html">
                    http://courses.media.mit.edu/2006fall/mas622j/Projects/aisen-project/index.html</a></description></item>
                 <item><description>
                   <a href="http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html">
                    http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html</a></description></item>
                 </list></para>
                 
             </remarks>
            
             <example>
               <code>
               // Sample data
               //   The following is simple auto association function
               //   where each input correspond to its own class. This
               //   problem should be easily solved by a Linear kernel.
            
               // Sample input data
               double[][] inputs =
               {
                   new double[] { 0 },
                   new double[] { 3 },
                   new double[] { 1 },
                   new double[] { 2 },
               };
               
               // Output for each of the inputs
               int[] outputs = { 0, 3, 1, 2 };
               
               
               // Create a new Linear kernel
               IKernel kernel = new Linear();
               
               // Create a new Multi-class Support Vector Machine with one input,
               //  using the linear kernel and for four disjoint classes.
               var machine = new MulticlassSupportVectorMachine(1, kernel, 4);
               
               // Create the Multi-class learning algorithm for the machine
               var teacher = new MulticlassSupportVectorLearning(machine, inputs, outputs);
               
               // Configure the learning algorithm to use SMO to train the
               //  underlying SVMs in each of the binary class subproblems.
               teacher.Algorithm = (svm, classInputs, classOutputs, i, j) =&gt;
                   new SequentialMinimalOptimization(svm, classInputs, classOutputs);
               
               // Run the learning algorithm
               double error = teacher.Run();
               </code>
             </example>
            
             <seealso cref="T:Accord.MachineLearning.VectorMachines.Learning.MulticlassSupportVectorLearning"/>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.#ctor(System.Int32,Accord.Statistics.Kernels.IKernel,System.Int32)">
            <summary>
              Constructs a new Multi-class Kernel Support Vector Machine
            </summary>
            <param name="kernel">The chosen kernel for the machine.</param>
            <param name="inputs">The number of inputs for the machine.</param>
            <param name="classes">The number of classes in the classification problem.</param>
            <remarks>
              If the number of inputs is zero, this means the machine
              accepts a indefinite number of inputs. This is often the
              case for kernel vector machines using a sequence kernel.
            </remarks>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.#ctor(Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine[][])">
            <summary>
              Constructs a new Multi-class Kernel Support Vector Machine
            </summary>
            <param name="machines">
              The machines to be used in each of the pairwise class subproblems.
            </param>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Accord#MachineLearning#VectorMachines#ISupportVectorMachine#Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Compute(System.Double[],System.Int32[]@)">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <param name="votes">A vector containing the number of votes for each class.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Item(System.Int32,System.Int32)">
            <summary>
              Gets the classifier for <paramref name="class1"/> against <paramref name="class2"/>.
            </summary>
            <remarks>
              If the index of <paramref name="class1"/> is greater than <paramref name="class2"/>,
              the classifier for the <paramref name="class2"/> against <paramref name="class1"/>
              will be returned instead. If both indices are equal, null will be
              returned instead.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Classes">
            <summary>
              Gets the number of classes.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Inputs">
            <summary>
              Gets the number of inputs of the machines.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.MulticlassSupportVectorMachine.Machines">
            <summary>
              Gets the subproblems classifiers.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine">
            <summary>
             Sparse Kernel Support Vector Machine (kSVM)
            </summary>
            <remarks>
            <para>
              The original optimal hyperplane algorithm (SVM) proposed by Vladimir Vapnik in 1963 was a
              linear classifier. However, in 1992, Bernhard Boser, Isabelle Guyon and Vapnik suggested
              a way to create non-linear classifiers by applying the kernel trick (originally proposed
              by Aizerman et al.) to maximum-margin hyperplanes. The resulting algorithm is formally
              similar, except that every dot product is replaced by a non-linear kernel function.</para>
            <para>
              This allows the algorithm to fit the maximum-margin hyperplane in a transformed feature space.
              The transformation may be non-linear and the transformed space high dimensional; thus though
              the classifier is a hyperplane in the high-dimensional feature space, it may be non-linear in
              the original input space.</para> 
            <para>
              References:
              <list type="bullet">
                <item><description><a href="http://en.wikipedia.org/wiki/Support_vector_machine">
                  http://en.wikipedia.org/wiki/Support_vector_machine</a></description></item>
                <item><description><a href="http://www.kernel-machines.org/">
                  http://www.kernel-machines.org/</a></description></item>
              </list></para>  
            </remarks>
            
            <example>
              <code>
              // Example XOR problem
              double[][] inputs =
              {
                  new double[] { 0, 0 }, // 0 xor 0: 1 (label +1)
                  new double[] { 0, 1 }, // 0 xor 1: 0 (label -1)
                  new double[] { 1, 0 }, // 1 xor 0: 0 (label -1)
                  new double[] { 1, 1 }  // 1 xor 1: 1 (label +1)
              };
              
              // Dichotomy SVM outputs should be given as [-1;+1]
              int[] labels =
              {
                  // 1,  0,  0, 1
                     1, -1, -1, 1
              };
              
              // Create a Kernel Support Vector Machine for the given inputs
              KernelSupportVectorMachine machine = new KernelSupportVectorMachine(new Gaussian(0.1), inputs[0].Length);
              
              // Instantiate a new learning algorithm for SVMs
              SequentialMinimalOptimization smo = new SequentialMinimalOptimization(machine, inputs, labels);
              
              // Set up the learning algorithm
              smo.Complexity = 1.0;
              
              // Run the learning algorithm
              double error = smo.Run();
              </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.#ctor(Accord.Statistics.Kernels.IKernel,System.Int32)">
            <summary>
              Creates a new Kernel Support Vector Machine.
            </summary>
            <param name="kernel">The chosen kernel for the machine.</param>
            <param name="inputs">The number of inputs for the machine.</param>
            <remarks>
              If the number of inputs is zero, this means the machine
              accepts a indefinite number of inputs. This is often the
              case for kernel vector machines using a sequence kernel.
            </remarks>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.Compute(System.Double[])">
            <summary>
              Computes the given input to produce the corresponding output.
            </summary>
            <param name="inputs">An input vector.</param>
            <returns>The output for the given input.</returns>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.KernelSupportVectorMachine.Kernel">
            <summary>
              Gets or sets the kernel used by this machine.
            </summary>
        </member>
    </members>
</doc>
